# LLM Provider Configuration
LLM_PROVIDER=gemini  # Default provider (ollama, openai, or gemini)

# Ollama Configuration
OLLAMA_API_URL=http://localhost:11434/api/generate
OLLAMA_DEFAULT_MODEL=deepseek-r1:7b

# OpenAI Configuration
OPENAI_API_URL=https://api.openai.com/v1/chat/completions
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo

# Google Gemini Configuration
GEMINI_API_KEY=
GEMINI_API_URL=https://generativelanguage.googleapis.com/v1beta/models
GEMINI_MODEL=gemini-1.5-flash  # or gemini-pro-vision for multimodal support

# Server Configuration
VITE_SERVER_URL=http://localhost:3000

# Client Origin Configuration
CLIENT_ORIGIN=http://localhost:5173

ENABLE_MATH_CHALLENGE=true
VITE_ENABLE_MATH_CHALLENGE=true